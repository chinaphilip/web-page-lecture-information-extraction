{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1870f511-4a91-4c4a-acd7-eb7806c0059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gemini/code\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3ad01-52cc-44af-b65a-6bf05b9d2314",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876136a5-b9b9-42fe-b0e7-9a4e3ef92906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir(\"code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889e2de-e005-4e49-8564-be4205904f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple transformers\n",
    "!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce40e6a9-55cb-43ac-ba04-5c51dfc15a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from modeling_big_bird import customBigBirdModel,customBigBirdForTokenClassification\n",
    "import json\n",
    "from BigBertconfig import BigBirdConfig,dict2obj\n",
    "from transformers import BigBirdModel,BertTokenizerFast,BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.utils.data as Data\n",
    "from utilfunction import padandtruncate\n",
    "import torch.distributed as dist\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "from torch.multiprocessing import Process\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from sklearn.utils import shuffle\n",
    "import pynvml\n",
    "from importlib import reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e351634-8327-459c-a337-cd9dbfb6bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/gemini/data-1/trainfilev6.csv\")\n",
    "for i in df.index:\n",
    "    df.at[i,\"xid4\"]=eval(df.at[i,\"xid4\"])\n",
    "    df.at[i,\"yid4\"]=eval(df.at[i,\"yid4\"])\n",
    "    df.at[i,\"tokenidlist\"]=eval(df.at[i,\"tokenidlist\"])\n",
    "    df.at[i,\"positionid3\"]=eval(df.at[i,\"positionid3\"])\n",
    "    df.at[i,\"labellist\"]=eval(df.at[i,\"labellist\"])\n",
    "df=shuffle(df,random_state=0)\n",
    "#df=df.iloc[:2700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd60b31a-6499-42ee-afd5-eb8432c657e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"tokenidlist\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af8ddf0-2480-47f1-badc-ae0b4eb11edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check data\n",
    "m=3001\n",
    "print(len(df.at[m,\"tokenidlist\"])==len(df.at[m,\"positionid3\"]))\n",
    "print(len(df.at[m,\"tokenidlist\"])==len(df.at[m,\"xid4\"]))\n",
    "print(len(df.at[m,\"tokenidlist\"])==len(df.at[m,\"yid4\"]))\n",
    "print(len(df.at[m,\"tokenidlist\"])==len(df.at[m,\"labellist\"]))\n",
    "print(df.at[m,\"labellist\"])\n",
    "#print(df.at[m,\"tokenlist\"])\n",
    "labelpos=np.argwhere(np.array(df.at[m,\"labellist\"])>0)\n",
    "print(np.take(df.at[m,\"tokenlist\"],labelpos),end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "172d47e4-75e5-48ff-bcf6-997fe8e59c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxtokenlength=2500#length blocksizepair(2400,40)(2400,60)(2200,40)(2200,55)(2048,32)\n",
    "xmaxlength=1000\n",
    "ymaxlength=3000\n",
    "maxpositionid=2500\n",
    "#df=shuffle(df,random_state=0)\n",
    "xidbatch=list(df[\"xid4\"])\n",
    "yidbatch=list(df[\"yid4\"])\n",
    "tokenbatch=list(df[\"tokenidlist\"])\n",
    "xidbatch=[[int(j) if j <xmaxlength else xmaxlength-1 for j in i]for i in xidbatch]\n",
    "yidbatch=[[int(j) if j <ymaxlength else ymaxlength-1 for j in i]for i in yidbatch]\n",
    "positionbatch=list(df[\"positionid3\"])\n",
    "positionbatch=[[int(j) if j <maxpositionid else maxpositionid-1  for j in i]for i in positionbatch]\n",
    "labelbatch=list(df[\"labellist\"])\n",
    "lengthlist=[len(i) for i in tokenbatch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0b50749-6c65-49df-9b08-c762b92a5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "xidbatch=padandtruncate(xidbatch,maxtokenlength,dtype=torch.int32)\n",
    "yidbatch=padandtruncate(yidbatch,maxtokenlength,dtype=torch.int32)\n",
    "positionbatch=padandtruncate(positionbatch,maxtokenlength,dtype=torch.int32)\n",
    "labelbatch=padandtruncate(labelbatch,maxtokenlength,dtype=torch.long,padvalue=0)#padvalue=-100 if not use crf else 0\n",
    "tokenbatch=padandtruncate(tokenbatch,maxtokenlength,dtype=torch.int32)\n",
    "maskbatch=tokenbatch>0\n",
    "maskbatch=maskbatch.type(torch.ByteTensor)\n",
    "classweight=torch.tensor([1,10,10,10,10,10,10,10,10],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c2d3b82-796d-492b-8f7f-2a9ae2ef2343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(maskbatch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf41788e-3c46-45ac-b76b-3500c41f85f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset = Data.TensorDataset(tokenbatch,positionbatch,xidbatch,yidbatch,labelbatch,maskbatch)\n",
    "train_set,val_set = torch.utils.data.random_split(torch_dataset, [2800, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad1b7900-ba42-4b44-9388-c66a4d3a83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', encoding='utf-8') as a:\n",
    "    # 读取文件\n",
    "    config = json.load(a)\n",
    "config = dict2obj(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da5d3231-5131-48ce-8a21-5d2f80e3320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transitionmatrix=torch.tensor([[0,0,-100,0,-100,0,-100,0,-100],\n",
    "[-100,-100,0,-100,-100,-100,-100,-100,-100],\n",
    "[0,0,0,0,-100,0,-100,0,-100],\n",
    "[-100,-100,-100,-100,0,-100,-100,-100,-100],\n",
    "[0,0,-100,0,0,0,-100,0,-100],\n",
    "[-100,-100,-100,-100,-100,-100,0,-100,-100],\n",
    "[0,0,-100,0,-100,0,0,0,-100],\n",
    "[-100,-100,-100,-100,-100,-100,-100,-100,0],\n",
    "[0,0,-100,0,-100,0,-100,0,0]])\n",
    "starttrasition=torch.tensor([0,0,-100,0,-100,0,-100,0,-100])\n",
    "endtransition=torch.tensor([0,-100,0,-100,0,-100,0,-100,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "323d86e7-7a6b-44fe-9b23-6d0adb9b3147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['crf.start_transitions', 'crf.end_transitions', 'crf.transitions'], unexpected_keys=[])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = customBigBirdForTokenClassification(config)\n",
    "model.load_state_dict(torch.load(\"modelsecondtrain.bin\"),strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de6089b4-6135-4e32-8c85-7047e37a6cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0., -100.,    0., -100.,    0., -100.,    0., -100.,    0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutomdict=model.state_dict()\n",
    "cutomdict[\"crf.transitions\"].copy_(transitionmatrix.clone())\n",
    "cutomdict[\"crf.start_transitions\"].copy_(starttrasition.clone())\n",
    "cutomdict[\"crf.end_transitions\"].copy_(endtransition.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ee4218-6fc9-4eaa-ac98-5678a776adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train process\n",
    "rank=0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_loader_train = torch.utils.data.DataLoader(dataset=train_set,batch_size=3)\n",
    "\n",
    "model = customBigBirdForTokenClassification(config)\n",
    "model.load_state_dict(torch.load(\"modelthirdtrain.bin\"),strict=False)\n",
    "model= model.to(device)\n",
    "classweight=classweight.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00004)\n",
    "accumulation_steps=12\n",
    "model.train()\n",
    "j=0\n",
    "for epoch in range(4):\n",
    "    print(\"epoch: \"+str(epoch))\n",
    "    for i,(tokenid,positionid,xid,yid,labelid,masklist) in enumerate(data_loader_train):\n",
    "        tokenid=tokenid.to(device)\n",
    "        positionid=positionid.to(device)\n",
    "        xid=xid.to(device)\n",
    "        yid=yid.to(device)\n",
    "        labelid=labelid.to(device)\n",
    "        masklist=masklist.to(device)\n",
    "        output = model(input_ids=tokenid,position_ids=positionid,x2d_ids=xid,y2d_ids=yid,labels=labelid,attention_mask=masklist,classweight=classweight)\n",
    "        #loss = output[0]/accumulation_steps #not use crf\n",
    "        loss = output/accumulation_steps     #use crf\n",
    "        loss.backward()\n",
    "        if((j+1)%accumulation_steps)==0:\n",
    "            # optimizer the net\n",
    "            optimizer.step()        # update parameters of net\n",
    "            optimizer.zero_grad()   # reset gradient\n",
    "        if i % 50 == 0:\n",
    "            print(\"loss: {}\".format(loss))\n",
    "        j=j+1\n",
    "\n",
    "torch.save(model.state_dict(), \"modelfourthtrain.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "817ed7cb-f747-4113-9b7a-1098862ea0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"modelsecondtrainwithmanualcrf.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1f10f-ec72-42ee-aa35-c1c2aa4938a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"modelv1.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "826998d5-6219-4a91-9545-731212fc3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "#print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba17fd8b-e69a-456f-ab86-642a1d2a1af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained(\"pretrainconfig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "194eec9c-f851-4119-b65f-bc80210e51da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['报', '告', '题', '目', '：', 'a', 'personal', '##ized', 'fed', '##erated', 'learning', 'framework', 'for', 'het', '##ero', '##gen', '##eous', 'population']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize('报告题目：A Personalized Federated Learning Framework for Heterogeneous Population'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "806b3b53-86ae-4dd2-83e0-549f376fcd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict not use crf\n",
    "model = customBigBirdForTokenClassification(config)\n",
    "model.load_state_dict(torch.load(\"modelsecondtrain.bin\"))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model= model.to(device)\n",
    "classweight=classweight.to(device)\n",
    "data_loader_val = torch.utils.data.DataLoader(dataset=val_set,batch_size=4)\n",
    "logitlist=[]\n",
    "tokenidlist=[]\n",
    "labelidlist=[]\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i,(tokenid,positionid,xid,yid,labelid,masklist) in enumerate(data_loader_val):\n",
    "        tokenid=tokenid.to(device)\n",
    "        positionid=positionid.to(device)\n",
    "        xid=xid.to(device)\n",
    "        yid=yid.to(device)\n",
    "        labelid=labelid.to(device)\n",
    "        masklist=masklist.to(device)\n",
    "        output = model(input_ids=tokenid,position_ids=positionid,x2d_ids=xid,y2d_ids=yid,labels=labelid,attention_mask=masklist,classweight=classweight)\n",
    "        logitlist.append(torch.argmax(output[1],dim=2))\n",
    "        tokenidlist.append(tokenid)\n",
    "        labelidlist.append(labelid)\n",
    "logitlist=torch.cat(logitlist,dim=0).cpu().detach().numpy()\n",
    "tokenidlist=torch.cat(tokenidlist,dim=0)\n",
    "labelidlist=torch.cat(labelidlist,dim=0).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0bb77cf-335d-488f-abda-8691056669da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpredict=pd.DataFrame(columns=[\"token/predict/true\"])\n",
    "for i in range(tokenidlist.shape[0]):\n",
    "    tokenlist=tokenizer.convert_ids_to_tokens(tokenidlist[i])\n",
    "    string=\"\"\n",
    "    for j in range(len(tokenidlist[i])):\n",
    "        string=string+tokenlist[j]+\"/\"+str(logitlist[i][j])+\"/\"+str(labelidlist[i][j])+\" \"\n",
    "    dfpredict.loc[i]=[string]\n",
    "dfpredict.to_csv(\"predictlist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b90ab0d-0427-47cc-872e-22a3076dd0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/gemini/data-3/predictfile.csv\")\n",
    "for i in df.index:\n",
    "    df.at[i,\"xid\"]=eval(df.at[i,\"xid\"])\n",
    "    df.at[i,\"yid\"]=eval(df.at[i,\"yid\"])\n",
    "    df.at[i,\"tokenid\"]=eval(df.at[i,\"tokenid\"])\n",
    "    df.at[i,\"positionid\"]=eval(df.at[i,\"positionid\"])\n",
    "df=shuffle(df,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd3a6c15-bcb4-4185-9ff8-dc555d4ff92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxtokenlength=2500#length blocksizepair(2400,40)(2400,60)(2200,40)(2200,55)(2048,32)\n",
    "xmaxlength=1000\n",
    "ymaxlength=3000\n",
    "maxpositionid=2500\n",
    "#df=shuffle(df,random_state=0)\n",
    "xidbatch=list(df[\"xid\"])\n",
    "yidbatch=list(df[\"yid\"])\n",
    "tokenbatch=list(df[\"tokenid\"])\n",
    "xidbatch=[[int(j) if j <xmaxlength else xmaxlength-1 for j in i]for i in xidbatch]\n",
    "yidbatch=[[int(j) if j <ymaxlength else ymaxlength-1 for j in i]for i in yidbatch]\n",
    "positionbatch=list(df[\"positionid\"])\n",
    "positionbatch=[[int(j) if j <maxpositionid else maxpositionid-1  for j in i]for i in positionbatch]\n",
    "lengthlist=[len(i) for i in tokenbatch]\n",
    "\n",
    "xidbatch=padandtruncate(xidbatch,maxtokenlength,dtype=torch.int32)\n",
    "yidbatch=padandtruncate(yidbatch,maxtokenlength,dtype=torch.int32)\n",
    "positionbatch=padandtruncate(positionbatch,maxtokenlength,dtype=torch.int32)\n",
    "tokenbatch=padandtruncate(tokenbatch,maxtokenlength,dtype=torch.int32)\n",
    "maskbatch=tokenbatch>0\n",
    "maskbatch=maskbatch.type(torch.ByteTensor)\n",
    "classweight=torch.tensor([1,10,10,10,10,10,10,10,10],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbce4777-0203-4388-8072-1bdbc0f1f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset = Data.TensorDataset(tokenbatch,positionbatch,xidbatch,yidbatch,maskbatch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd3cf528-2e19-48d5-bbac-f1f1d6d27159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict use crf\n",
    "model = customBigBirdForTokenClassification(config)\n",
    "model.load_state_dict(torch.load(\"modelsecondtrainwithmanualcrf.bin\"))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model= model.to(device)\n",
    "classweight=classweight.to(device)\n",
    "data_loader_val = torch.utils.data.DataLoader(dataset=predict_dataset,batch_size=4)\n",
    "#logitlist=[]\n",
    "tokenidlist=[]\n",
    "logitlist=[]\n",
    "#labelidlist=[]\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i,(tokenid,positionid,xid,yid,masklist) in enumerate(data_loader_val):\n",
    "        tokenid=tokenid.to(device)\n",
    "        positionid=positionid.to(device)\n",
    "        xid=xid.to(device)\n",
    "        yid=yid.to(device)\n",
    "        #labelid=labelid.to(device)\n",
    "        masklist=masklist.to(device)\n",
    "        output = model(input_ids=tokenid,position_ids=positionid,x2d_ids=xid,y2d_ids=yid,attention_mask=masklist,classweight=classweight)#labels=labelid\n",
    "        tokenidlist.append(tokenid)\n",
    "        logitlist.append(output)\n",
    "tokenidlist=torch.cat(tokenidlist,dim=0)\n",
    "logitlist=[j for i in range(len(logitlist)) for j in logitlist[i]]\n",
    "#labelidlist=torch.cat(labelidlist,dim=0).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dd35b08-55a8-4eca-9dfd-b0598e92c60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "print(len(logitlist[0]))\n",
    "print(len(tokenidlist[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eafcd137-f8a9-41a6-845c-a2f9a533a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpredict=pd.DataFrame(columns=[\"tokenwithid\"])\n",
    "for i in range(tokenidlist.shape[0]):\n",
    "    tokenlist=tokenizer.convert_ids_to_tokens(tokenidlist[i])\n",
    "    string=\"\"\n",
    "    for j in range(len(logitlist[i])):\n",
    "        string=string+tokenlist[j]+\"/\"+str(logitlist[i][j])+\" \"\n",
    "    dfpredict.loc[i]=[string,]\n",
    "dfpredict.to_csv(\"predictnewfilelistwithcrf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82c4a352-56af-46b1-bcfc-60aea8d869c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logitlist=logitlist.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c792884f-d980-4acf-8cd5-0d18cfddc2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpredict.to_csv(\"predictlist.csv\",encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "460f522c-743a-451c-898e-a22441f1670e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24258.0\n",
      "4247.265625\n",
      "20010.734375\n"
     ]
    }
   ],
   "source": [
    "pynvml.nvmlInit()\n",
    "handle = pynvml.nvmlDeviceGetHandleByIndex(0) # 0表示显卡标号\n",
    "meminfo = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "print(meminfo.total/1024**2) #总的显存大小\n",
    "print(meminfo.used/1024**2)  #已用显存大小\n",
    "print(meminfo.free/1024**2)  #剩余显存大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d74763-497b-497a-9e9f-739f2221f8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b44222-c08b-4099-8fce-5caef4b91778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
